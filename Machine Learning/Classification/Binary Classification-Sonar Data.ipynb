{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('sonar.all-data.csv',, header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0232</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029208</td>\n",
       "      <td>0.038443</td>\n",
       "      <td>0.043837</td>\n",
       "      <td>0.054053</td>\n",
       "      <td>0.075105</td>\n",
       "      <td>0.104599</td>\n",
       "      <td>0.121591</td>\n",
       "      <td>0.134677</td>\n",
       "      <td>0.177361</td>\n",
       "      <td>0.208245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.013472</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.006523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023038</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>0.046583</td>\n",
       "      <td>0.055669</td>\n",
       "      <td>0.059247</td>\n",
       "      <td>0.061897</td>\n",
       "      <td>0.085340</td>\n",
       "      <td>0.118311</td>\n",
       "      <td>0.134741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.005038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.024450</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.066950</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.080350</td>\n",
       "      <td>0.096750</td>\n",
       "      <td>0.111150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>0.152200</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.101050</td>\n",
       "      <td>0.134150</td>\n",
       "      <td>0.153050</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.016750</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.008550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0.0200      0.0371      0.0428      0.0207      0.0954      0.0986  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000  207.000000  207.000000   \n",
       "mean     0.029208    0.038443    0.043837    0.054053    0.075105    0.104599   \n",
       "std      0.023038    0.033040    0.038521    0.046583    0.055669    0.059247   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013300    0.016400    0.018900    0.024450    0.037700    0.066950   \n",
       "50%      0.022800    0.030800    0.034200    0.044100    0.062000    0.092100   \n",
       "75%      0.035800    0.048100    0.058200    0.065700    0.101050    0.134150   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "           0.1539      0.1601      0.3109      0.2111  ...      0.0232  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000  ...  207.000000   \n",
       "mean     0.121591    0.134677    0.177361    0.208245  ...    0.016034   \n",
       "std      0.061897    0.085340    0.118311    0.134741  ...    0.012027   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080600    0.080350    0.096750    0.111150  ...    0.008350   \n",
       "50%      0.105600    0.111900    0.152200    0.181000  ...    0.013800   \n",
       "75%      0.153050    0.169800    0.231500    0.269000  ...    0.020700   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "           0.0027      0.0065      0.0159      0.0072      0.0167      0.0180  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000  207.000000  207.000000   \n",
       "mean     0.013472    0.010729    0.010917    0.009300    0.008181    0.007771   \n",
       "std      0.009628    0.007071    0.007310    0.007103    0.005719    0.005756   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007350    0.005050    0.005350    0.004100    0.004400    0.003700   \n",
       "50%      0.011500    0.009600    0.009300    0.007500    0.006800    0.005900   \n",
       "75%      0.016750    0.014900    0.014450    0.012100    0.010350    0.010350   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "           0.0084      0.0090      0.0032  \n",
       "count  207.000000  207.000000  207.000000  \n",
       "mean     0.007947    0.007936    0.006523  \n",
       "std      0.006485    0.006196    0.005038  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003650    0.003100  \n",
       "50%      0.005800    0.006300    0.005300  \n",
       "75%      0.010400    0.010350    0.008550  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate algorithms\n",
    "# Get test and validation set\n",
    "array = dataset.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = array[:,0:60].astype(float)\n",
    "Y = array[:,60]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(\n",
    "    X, Y, test_size = validation_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR:     0.758:     (0.065)\n",
      "LDA:     0.702:     (0.086)\n",
      "KNN:     0.757:     (0.112)\n",
      "CART:     0.751:     (0.107)\n",
      "NB:     0.700:     (0.132)\n",
      "SVM:     0.547:     (0.106)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy of SVM model: 0.762\n",
      "\n",
      " Accuracy of DecisionTress model: 0.643\n",
      "\n",
      " Confusion matrix: \n",
      " [[17  9]\n",
      " [ 6 10]]\n",
      "\n",
      " Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          M       0.74      0.65      0.69        26\n",
      "          R       0.53      0.62      0.57        16\n",
      "\n",
      "avg / total       0.66      0.64      0.65        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spot check algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "kFoldsplits = 10\n",
    "print(\"\")\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = kFoldsplits, random_state = seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring = scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(\"{}:     {}:     ({})\".format(name, format(cv_results.mean(), '.3f'), format(cv_results.std(), '.3f')))\n",
    "\n",
    "# Compare algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Making predictions\n",
    "SVM = SVC()\n",
    "SVM.fit(X_train, Y_train)\n",
    "predictions = SVM.predict(X_validation)\n",
    "SVCacc_score = accuracy_score(Y_validation, predictions)\n",
    "\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train, Y_train)\n",
    "predictions = DT.predict(X_validation)\n",
    "DTacc_score = accuracy_score(Y_validation, predictions)\n",
    "\n",
    "\n",
    "print(\"\\n\", \"Accuracy of SVM model: {}\".format(format(SVCacc_score,'.3f')))\n",
    "print(\"\\n\", \"Accuracy of DecisionTress model: {}\".format(format(DTacc_score,'.3f')))\n",
    "print(\"\\n\", \"Confusion matrix: \\n\", confusion_matrix(Y_validation, predictions))\n",
    "print(\"\\n\", \"Classification report: \\n\", classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 81.47% (7.08%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 85.54% (4.17%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline model with standardized dataset\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller model\n",
    "def create_smaller():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 85.50% (5.23%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger model\n",
    "def create_larger():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 86.47% (4.67%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
